---
title: Create Agent
description: Defining the personality, context, and opening behavior of your Voice AI.
---

import { Step, Steps } from 'fumadocs-ui/components/steps';
import { User, Library, Mic, Settings2, Sparkles, AlertTriangle } from 'lucide-react';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

The **Agent** represents the "Persona" of your Voice AI. While the Script handles the logic flow, the Agent defines *who* is speaking, what they know about your brand, and how they behave tonally.

## Creating an Agent

Navigate to **Agent Studio** -> **Agents** and click **Add Agent**.

<Steps>
<Step>
### General Information
Give your agent an internal name (e.g., "Iqra - Sales") and a description. This helps you identify them when assigning them to campaigns later.
</Step>

<Step>
### Context Injection
Instead of manually typing your company address or pricing into every prompt, you can "Inject" structured data from your **[Business Context](/build/knowledge/context)**.

*   **Branding:** Company name, website, support email.
*   **Services/Products:** The list of items you sell (Name, Short Description).
*   **Branches:** Locations and working hours.

<Callout type="info" title="Token Optimization">
  Only inject what is necessary. If an agent is for "Technical Support", do not inject the entire "Sales Product Catalog". This saves tokens and reduces hallucinations.
</Callout>
</Step>

<Step>
### Personality (The System Prompt)
This is the most critical section. You are constructing the **System Prompt** that governs the LLM's behavior.

*   **Role:** Who is the agent? (e.g., "You are an official AI agent for Badal Technologies.")
*   **Capabilities:** What can it do? (e.g., "You have access to the knowledge base system.")
*   **Ethics:** The boundaries. (e.g., "You are a Muslim agent with the ethics of the Prophet (SAW)." or "You never ask for passwords.")
*   **Tone:** The vibe. (e.g., "Treat the user with care and respect. Start responses with a polite greeting like 'Salam'.")

<Callout type="warn" title="Multi-Language Requirement">
  You must define these fields for **every language** enabled in your business. This ensures your Arabic agent has the correct cultural nuance (e.g., using "Salam") compared to the English agent.
</Callout>
</Step>

<Step>
### Utterances (Greetings)
Define how the call starts.

*   **Agent Speaks First:**
    *   **Enabled:** Standard for Outbound. The agent speaks immediately.
    *   **Disabled:** Standard for Inbound. The agent waits for the user to say "Hello?".
*   **Greeting Message:** The exact text spoken. Supports [Templating](/build/script/templating) (e.g., `Salam {{ name }}`).
</Step>
</Steps>

## Pro Tips: Prompt Engineering

How to write instructions that actually work.

<Accordions>
  <Accordion title="Write Instructions, Not Adjectives">
    **Bad:** `Tone: Polite`
    
    **Good:** `Tone: Treat the user with care and respect. Start responses with a polite greeting when appropriate (e.g., "Welcome to Badal Technologies", "Salam").`
    
    *Why:* LLMs follow instructions better than abstract keywords. Tell it *how* to be polite.
  </Accordion>

  <Accordion title="Define the Negative Space">
    **Bad:** `Be helpful.`
    
    **Good:** `Ethics: Do not engage in vague, idle, or spam conversations. If someone forces you to, end the call.`
    
    *Why:* Defining what the agent *should not* do is as important as what it *should* do to prevent jailbreaks.
  </Accordion>

  <Accordion title="Give it an Identity">
    **Bad:** `You are a bot.`
    
    **Good:** `Role: You are Iqra, an official AI agent for Badal Technologies Oman. Your role is to help the user while putting their needs first.`
    
    *Why:* Giving the agent a name and a specific employer helps ground its responses in a specific context.
  </Accordion>
</Accordions>

## Environment (Background Audio)

To make calls feel more natural and less "robotic," you can inject a continuous background audio loop.

*   **Use Cases:**
    *   **Call Center:** Subtle typing and murmuring sounds.
    *   **Office:** HVAC hum and distant phone rings.
    *   **Cafe:** Clinking cups (for casual agents).
*   **Configuration:** Upload an MP3/WAV file. The platform handles the loop mixing automatically.

<Callout type="tip" title="Psychological Effect">
  Adding a low-volume background track significantly reduces the "Uncanny Valley" effect and makes users more forgiving of small latencies.
</Callout>

## Next Steps

Once the Persona is defined, configure the "Senses" and "Brain".

<Cards>
  <Card icon={<Mic />} title="Interruption Engine" href="/build/agent/interruption">
    Configure **VAD** and **Turn-Taking** logic to handle interruptions naturally.
  </Card>
  <Card icon={<Settings2 />} title="Intelligence & Integrations" href="/build/agent/intelligence">
    Connect specific LLM models, TTS voices, and Fallback providers.
  </Card>
  <Card icon={<Library />} title="Knowledge Base" href="/build/agent/intelligence#knowledge-base">
    Connect RAG documents and define search triggers.
  </Card>
</Cards>